{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PhraseId', 'SentenceId', 'Phrase', 'Sentiment']\n",
      "   PhraseId  SentenceId  \\\n",
      "0         1           1   \n",
      "1         2           1   \n",
      "2         3           1   \n",
      "3         4           1   \n",
      "4         5           1   \n",
      "\n",
      "                                                                                                                                                                                         Phrase  \\\n",
      "0  A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .   \n",
      "1                                                                                                                 A series of escapades demonstrating the adage that what is good for the goose   \n",
      "2                                                                                                                                                                                      A series   \n",
      "3                                                                                                                                                                                             A   \n",
      "4                                                                                                                                                                                        series   \n",
      "\n",
      "   Sentiment  \n",
      "0          1  \n",
      "1          2  \n",
      "2          2  \n",
      "3          2  \n",
      "4          2  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns',50)\n",
    "train_raw=pd.read_csv('train.tsv',delimiter='\\t',encoding='utf-8')\n",
    "print(list(train_raw.columns.values)) #file header\n",
    "print(train_raw.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.Phrase[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PhraseId  SentenceId  \\\n",
      "0    156061        8545   \n",
      "1    156062        8545   \n",
      "2    156063        8545   \n",
      "3    156064        8545   \n",
      "4    156065        8545   \n",
      "\n",
      "                                                   Phrase  \n",
      "0  An intermittently pleasing but mostly routine effort .  \n",
      "1    An intermittently pleasing but mostly routine effort  \n",
      "2                                                      An  \n",
      "3       intermittently pleasing but mostly routine effort  \n",
      "4              intermittently pleasing but mostly routine  \n"
     ]
    }
   ],
   "source": [
    "test_raw=pd.read_csv('test.tsv',delimiter='\\t',encoding='utf-8')\n",
    "print(test_raw.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_clean=[]\n",
    "for i in range(len(train_raw)):\n",
    "    # filter out punctuation\n",
    "    text=train_raw.Phrase[i]\n",
    "    tokens = word_tokenize(text)\n",
    "    # convert to lower case\n",
    "    tokens=[w.lower() for w in tokens]\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    # lemmatize the data\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "    phrase_clean.append(' '.join(word for word in stemmed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean test data\n",
    "test_phrase_clean=[]\n",
    "for i in range(len(test_raw)):\n",
    "    # filter out punctuation\n",
    "    text=test_raw.Phrase[i]\n",
    "    tokens = word_tokenize(text)\n",
    "    # convert to lower case\n",
    "    tokens=[w.lower() for w in tokens]\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    # lemmatize the data\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "    test_phrase_clean.append(' '.join(word for word in stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine effort .</td>\n",
       "      <td>an intermitt pleas but mostli routin effort</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId  \\\n",
       "0    156061        8545   \n",
       "\n",
       "                                                   Phrase  \\\n",
       "0  An intermittently pleasing but mostly routine effort .   \n",
       "\n",
       "                                  clean_review  \n",
       "0  an intermitt pleas but mostli routin effort  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "test_phrase_tidy=DataFrame(test_phrase_clean)\n",
    "test_clean=pd.concat([test_raw,test_phrase_tidy],axis=1,sort=False)\n",
    "test_clean=test_clean.rename(columns={0:'clean_review'})\n",
    "test_clean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
       "      <td>1</td>\n",
       "      <td>a seri of escapad demonstr the adag that what is good for the goos is also good for the gander some of which occasion amus but none of which amount to much of a stori</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId  \\\n",
       "0         1           1   \n",
       "\n",
       "                                                                                                                                                                                         Phrase  \\\n",
       "0  A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .   \n",
       "\n",
       "   Sentiment  \\\n",
       "0          1   \n",
       "\n",
       "                                                                                                                                                             clean_review  \n",
       "0  a seri of escapad demonstr the adag that what is good for the goos is also good for the gander some of which occasion amus but none of which amount to much of a stori  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train data\n",
    "phrase_tidy=DataFrame(phrase_clean)\n",
    "train_clean=pd.concat([train_raw,phrase_tidy],axis=1,sort=False)\n",
    "train_clean=train_clean.rename(columns={0:'clean_review'})\n",
    "train_clean.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "full_text=list(train_clean['clean_review'].values)+list(test_clean['clean_review'].values)\n",
    "vectorizer.fit(full_text)\n",
    "df_upsampled_vectorized=vectorizer.transform(train_clean['clean_review'])\n",
    "test_vectorized=vectorizer.transform(test_clean['clean_review'])\n",
    "test1=test_clean['clean_review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation mean accuracy 58.49%, std 0.068792.\n"
     ]
    }
   ],
   "source": [
    "logreg=LogisticRegression()\n",
    "ovr=OneVsRestClassifier(logreg)\n",
    "ovr.fit(df_upsampled_vectorized, train_clean['Sentiment'])\n",
    "scores=cross_val_score(ovr,df_upsampled_vectorized,train_clean['Sentiment'],scoring='accuracy', n_jobs=-1,cv=3)\n",
    "print('Cross-validation mean accuracy {0:.2f}%, std {1:2f}.'.format(np.mean(scores)*100,np.std(scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred=ovr.fit(df_upsampled_vectorized, train_clean['Sentiment']).predict(test_vectorized)\n",
    "pred_df=DataFrame(pred)\n",
    "pred_df=pred_df.rename(columns={0:'Sentiment'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  Sentiment\n",
       "0    156061          3\n",
       "1    156062          3\n",
       "2    156063          2\n",
       "3    156064          3\n",
       "4    156065          3"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df=pd.DataFrame({'PhraseId': test_raw.PhraseId, 'Sentiment': pred_df.Sentiment})\n",
    "sub_df.to_csv('sentiment_prediction.csv',index=False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
